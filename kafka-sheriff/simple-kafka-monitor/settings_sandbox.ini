[kafka]
bootstrap_servers = [ "kafka1.example.com:9096","kafka2.example.com:9096","kafka3.example.com:9096", "kafka4.example.com:9096" ]
# input and output topics and groups
topic = inboundtopic
group_id = grp_input
outbound_topic = outboundtopic
outbound_group_id = grp_output
auto_offset_reset=latest
# All the security configuration. It also takes care of Kerberos
# PLAINTEXT or SASL_SSL
protocol = SASL_SSL
# Example location is given. Change it as per your case.
ssl_cafile=/etc/security/certs/ca.pem
ssl_certfile=/etc/security/certs/cert.pem
ssl_keyfile=/etc/security/certs/key.pem
ssl_password=None
sasl_mechanism=GSSAPI
keytab_retry_limit=5
keytab_retry_interval=10
connection_timeout=10

[http]
# This is for the internal http server
http_host=
http_port=8080
http_ssl_port=8443
http_ssl_enabled=False
http_cert_file=/etc/security/certs/cert.pem
threaded=False
context_root=bpmon

[cache]
# Cache will store the metrics. It can be an inbuilt cache or an external redis cache
#type can take redis and internal
type=redis
interval=10
cache_expiration_time.seconds=300
sliding_window = 10

[internal_cache]
cache_server_host=localhost
cache_server_port=8010
cache_max_size=10

[redis]
redis_host=
redis_port=6379
redis_db=2

[log]
location=/var/log/
# change out_type only for testing to file
out_type=stdout
consumer_log_level=DEBUG

[kerberos]
# The configuration is tighlt coupled to s3. TODO: Make it generic.
keytab_s3_bucket=
keytab_s3_key=
login_retry=2
#poll is in seconds
login_retry_poll=3
kerberos_principal=
keytab_local_path=/etc/security/keytabs/kafka.headless.keytab
kinit_refresh_interval=60

[ssl]
ssl_bucket=
ssl_certs=[
    {"src":"ssl/ca.pem", "dst":"/etc/security/certs/ca.pem", "srctype":"s3",  "overwrite":"True"}
    , {"src":"ssl/cert.pem", "dst":"/etc/security/certs/cert.pem", "srctype":"s3",  "overwrite":"True"}
    , {"src":"ssl/key.pem", "dst":"/etc/security/certs/key.pem", "srctype":"s3",  "overwrite":"True"}
    ]